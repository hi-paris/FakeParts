[{"regression": false, "start": "lora_unet_", "end": ""}, {"regression": false, "start": "up_blocks_", "end": "up_blocks."}, {"regression": false, "start": "down_blocks_", "end": "down_blocks."}, {"regression": false, "start": "_attentions_", "end": ".attentions."}, {"regression": false, "start": "_transformer_blocks_", "end": ".transformer_blocks."}, {"regression": false, "start": "_attn", "end": ".attn"}, {"regression": false, "start": "_ff", "end": ".ff"}, {"regression": false, "start": "_to", "end": ".to"}, {"regression": false, "start": "ff_", "end": "ff."}, {"regression": false, "start": "net_", "end": "net."}, {"regression": false, "start": "_proj", "end": ".proj"}, {"regression": false, "start": "to_out_", "end": "to_out."}, {"regression": false, "start": "lora_te_", "end": ""}, {"regression": false, "start": "text_model_", "end": "text_model."}, {"regression": false, "start": "text_model.encoder_", "end": "text_model.encoder."}, {"regression": false, "start": "encoder.layers_", "end": "encoder.layers."}, {"regression": false, "start": "_self.attn_", "end": ".self_attn."}, {"regression": false, "start": "attn.out.proj", "end": "attn.out_proj"}, {"regression": false, "start": ".q.proj.", "end": ".q_proj."}, {"regression": false, "start": ".v.proj.", "end": ".v_proj."}, {"regression": false, "start": "_mlp_", "end": ".mlp."}, {"regression": false, "start": ".k.proj.", "end": ".k_proj."}, {"regression": false, "start": "_resnets_", "end": ".resnets."}, {"regression": false, "start": "_conv", "end": ".conv"}, {"regression": false, "start": "_time_emb.proj", "end": ".time_emb_proj"}, {"regression": false, "start": "_upsamplers_", "end": ".upsamplers."}, {"regression": false, "start": "_downsamplers_", "end": ".downsamplers."}, {"regression": true, "start": "(\\d+)\\.(\\d+)\\.transformer_blocks", "end": "\\1.attentions.\\2.transformer_blocks"}, {"regression": true, "start": "(\\d+)\\.(\\d+)\\.", "end": "\\1.resnets.\\2."}]
